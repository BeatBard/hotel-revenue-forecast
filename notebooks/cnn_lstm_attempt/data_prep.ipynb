{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTER_NAME   = \"RevenueCenter_1\"\n",
    "DATA_DIR      = \"revenue_center_data\"\n",
    "FILE_PATH     = os.path.join(DATA_DIR, f\"{CENTER_NAME}_data.csv\")\n",
    "LOW_IMPACT    = [\"IsArtDubai\", \"IsFilmFestival\", \"IsWorldCup\"]\n",
    "FORECAST_DAYS = 90            # ≈ three months\n",
    "VALID_START   = \"2023-10-01\"  # use last 3 months for validation\n",
    "\n",
    "\n",
    "# Numeric encoding maps  ------------------------------------------\n",
    "TI_MAP = {\"Low\": 0, \"Normal\": 1, \"Medium\": 2, \"High\": 3}\n",
    "RI_MAP = {\"Decrease\": -1, \"Neutral\": 0, \"Boost\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pre-processing done → (1458, 26)\n",
      "        Date MealPeriod RevenueCenterName  DayOfWeek  Month  Year  CheckTotal  \\\n",
      "0 2023-01-01  Breakfast   RevenueCenter_1          6      1  2023      1499.4   \n",
      "1 2023-01-01     Dinner   RevenueCenter_1          6      1  2023      4374.5   \n",
      "\n",
      "   is_zero          IslamicPeriod  IsRamadan  ...  IsNationalDay  IsNewYear  \\\n",
      "0        0  New-Year-Celebrations          0  ...              0          1   \n",
      "1        0  New-Year-Celebrations          0  ...              0          1   \n",
      "\n",
      "   IsMarathon  IsGITEX  IsAirshow  IsFoodFestival  IsPreEvent  IsPostEvent  \\\n",
      "0           0        0          0               0           0            0   \n",
      "1           0        0          0               0           0            0   \n",
      "\n",
      "   TourismIntensity  RevenueImpact  \n",
      "0                 3              1  \n",
      "1                 3              1  \n",
      "\n",
      "[2 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = os.path.join(\"..\", DATA_DIR, f\"{CENTER_NAME}_data.csv\")\n",
    "assert os.path.exists(FILE_PATH), f\"CSV not found → {FILE_PATH}\"\n",
    "raw = pd.read_csv(FILE_PATH, parse_dates=[\"Date\"])\n",
    "\n",
    "raw.drop(columns=[c for c in LOW_IMPACT if c in raw.columns], inplace=True, errors=\"ignore\")\n",
    "\n",
    "for col in [\"Date\", \"MealPeriod\", \"CheckTotal\"]:\n",
    "    if col not in raw.columns:\n",
    "        raise KeyError(f\"Missing column: {col}\")\n",
    "\n",
    "flag_cols = [c for c in raw.columns if c.startswith(\"Is\") and c != \"IslamicPeriod\"]\n",
    "for f in flag_cols:\n",
    "    raw[f] = raw[f].fillna(0).astype(int)\n",
    "\n",
    "raw[\"TourismIntensity\"] = raw[\"TourismIntensity\"].map(TI_MAP).fillna(1).astype(int)\n",
    "raw[\"RevenueImpact\"] = raw[\"RevenueImpact\"].map(RI_MAP).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "print(\"✓ Pre-processing done →\", raw.shape)\n",
    "print(raw.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains zero values: False\n",
      "Number of zeros: 0\n"
     ]
    }
   ],
   "source": [
    "# Simple check for zero values in CheckTotal\n",
    "has_zeros = (raw['CheckTotal'] == 0).any()\n",
    "zero_count = (raw['CheckTotal'] == 0).sum()\n",
    "\n",
    "print(f\"Contains zero values: {has_zeros}\")\n",
    "print(f\"Number of zeros: {zero_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing zero values with 30-day rolling average...\n",
      "✓ Zero replacement complete\n",
      "✓ Remaining zeros: 0\n"
     ]
    }
   ],
   "source": [
    "# Replace zero values with 30-day rolling average\n",
    "print(\"Replacing zero values with 30-day rolling average...\")\n",
    "\n",
    "# Check if we need to group by specific columns\n",
    "groupby_cols = []\n",
    "if 'RevenueCenterName' in raw.columns:\n",
    "    groupby_cols.append('RevenueCenterName')\n",
    "if 'MealPeriod' in raw.columns:\n",
    "    groupby_cols.append('MealPeriod')\n",
    "\n",
    "# Sort by date for proper time series processing\n",
    "raw = raw.sort_values(['Date'] + groupby_cols)\n",
    "\n",
    "# Function to replace zeros with rolling average\n",
    "def replace_zeros_with_average(series):\n",
    "    # Create a copy to avoid modifying original\n",
    "    result = series.copy()\n",
    "    \n",
    "    # Calculate 30-day rolling average (centered window)\n",
    "    rolling_avg = series.rolling(window=30, center=True, min_periods=5).mean()\n",
    "    \n",
    "    # For edge cases, use backward-looking average\n",
    "    rolling_avg_backward = series.rolling(window=30, min_periods=5).mean()\n",
    "    \n",
    "    # Fill NaN values in centered average with backward-looking average\n",
    "    rolling_avg = rolling_avg.fillna(rolling_avg_backward)\n",
    "    \n",
    "    # Replace zeros with rolling average\n",
    "    zero_mask = (result == 0)\n",
    "    result[zero_mask] = rolling_avg[zero_mask]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply the replacement\n",
    "if groupby_cols:\n",
    "    # Group by RevenueCenterName and MealPeriod if they exist\n",
    "    raw['CheckTotal'] = raw.groupby(groupby_cols)['CheckTotal'].transform(replace_zeros_with_average)\n",
    "else:\n",
    "    # Apply to entire series if no grouping needed\n",
    "    raw['CheckTotal'] = replace_zeros_with_average(raw['CheckTotal'])\n",
    "\n",
    "# Check results\n",
    "remaining_zeros = (raw['CheckTotal'] == 0).sum()\n",
    "print(f\"✓ Zero replacement complete\")\n",
    "print(f\"✓ Remaining zeros: {remaining_zeros}\")\n",
    "\n",
    "# Handle any remaining zeros (edge cases) with forward/backward fill\n",
    "if remaining_zeros > 0:\n",
    "    if groupby_cols:\n",
    "        raw['CheckTotal'] = raw.groupby(groupby_cols)['CheckTotal'].transform(\n",
    "            lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
    "        )\n",
    "    else:\n",
    "        raw['CheckTotal'] = raw['CheckTotal'].fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    final_zeros = (raw['CheckTotal'] == 0).sum()\n",
    "    print(f\"✓ Final zeros after fill: {final_zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data to CSV\n",
    "output_path = os.path.join(\"..\", DATA_DIR, f\"{CENTER_NAME}_preprocessed.csv\")\n",
    "raw.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: ['Date', 'MealPeriod', 'RevenueCenterName', 'DayOfWeek', 'Month', 'Year', 'CheckTotal', 'is_zero', 'IslamicPeriod', 'IsRamadan', 'IsEid', 'IsPreRamadan', 'IsPostRamadan', 'IsLast10Ramadan', 'IsDSF', 'IsSummerEvent', 'IsNationalDay', 'IsNewYear', 'IsMarathon', 'IsGITEX', 'IsAirshow', 'IsFoodFestival', 'IsPreEvent', 'IsPostEvent', 'TourismIntensity', 'RevenueImpact']\n",
      "Data types:\n",
      "Date                 datetime64[ns]\n",
      "MealPeriod                   object\n",
      "RevenueCenterName            object\n",
      "DayOfWeek                     int64\n",
      "Month                         int64\n",
      "Year                          int64\n",
      "CheckTotal                  float64\n",
      "is_zero                       int64\n",
      "IslamicPeriod                object\n",
      "IsRamadan                     int32\n",
      "IsEid                         int32\n",
      "IsPreRamadan                  int32\n",
      "IsPostRamadan                 int32\n",
      "IsLast10Ramadan               int32\n",
      "IsDSF                         int32\n",
      "IsSummerEvent                 int32\n",
      "IsNationalDay                 int32\n",
      "IsNewYear                     int32\n",
      "IsMarathon                    int32\n",
      "IsGITEX                       int32\n",
      "IsAirshow                     int32\n",
      "IsFoodFestival                int32\n",
      "IsPreEvent                    int32\n",
      "IsPostEvent                   int32\n",
      "TourismIntensity              int32\n",
      "RevenueImpact                 int32\n",
      "dtype: object\n",
      "\n",
      "Dropping non-feature columns: ['Date', 'RevenueCenterName']\n",
      "\n",
      "String columns to one-hot encode: ['MealPeriod', 'IslamicPeriod']\n",
      "\n",
      "One-hot encoding 'MealPeriod':\n",
      "  Unique values: ['Breakfast' 'Dinner' 'Lunch']\n",
      "  Created columns: ['MealPeriod_Breakfast', 'MealPeriod_Dinner', 'MealPeriod_Lunch']\n",
      "\n",
      "One-hot encoding 'IslamicPeriod':\n",
      "  Unique values: ['New-Year-Celebrations' 'Post-New-Year-Celebrations' 'Normal'\n",
      " 'Pre-Dubai-Marathon' 'Dubai-Marathon' 'Post-Dubai-Marathon'\n",
      " 'Pre-Dubai-Food-Festival' 'Dubai-Food-Festival' 'Pre-Ramadan-Early'\n",
      " 'Pre-Ramadan-Late' 'Ramadan-First10Days' 'Ramadan-Middle'\n",
      " 'Ramadan-Last10Days' 'Post-Ramadan-Week1' 'Post-Ramadan-Recovery'\n",
      " 'Pre-Eid-Adha' 'Eid-Adha' 'Post-Eid-Adha' 'Dubai-Summer-Surprises'\n",
      " 'Post-Summer-Event' 'Pre-GITEX-Technology-Week' 'GITEX-Technology-Week'\n",
      " 'Post-GITEX-Technology-Week' 'Pre-Flag-Day' 'Flag-Day' 'Post-Flag-Day'\n",
      " 'Pre-Dubai-Airshow' 'Dubai-Airshow' 'Post-Dubai-Airshow'\n",
      " 'Pre-Commemoration-Day' 'Pre-UAE-National-Day' 'Pre-DSF'\n",
      " 'Dubai-Shopping-Festival']\n",
      "  Created columns: ['IslamicPeriod_Dubai-Airshow', 'IslamicPeriod_Dubai-Food-Festival', 'IslamicPeriod_Dubai-Marathon', 'IslamicPeriod_Dubai-Shopping-Festival', 'IslamicPeriod_Dubai-Summer-Surprises', 'IslamicPeriod_Eid-Adha', 'IslamicPeriod_Flag-Day', 'IslamicPeriod_GITEX-Technology-Week', 'IslamicPeriod_New-Year-Celebrations', 'IslamicPeriod_Normal', 'IslamicPeriod_Post-Dubai-Airshow', 'IslamicPeriod_Post-Dubai-Marathon', 'IslamicPeriod_Post-Eid-Adha', 'IslamicPeriod_Post-Flag-Day', 'IslamicPeriod_Post-GITEX-Technology-Week', 'IslamicPeriod_Post-New-Year-Celebrations', 'IslamicPeriod_Post-Ramadan-Recovery', 'IslamicPeriod_Post-Ramadan-Week1', 'IslamicPeriod_Post-Summer-Event', 'IslamicPeriod_Pre-Commemoration-Day', 'IslamicPeriod_Pre-DSF', 'IslamicPeriod_Pre-Dubai-Airshow', 'IslamicPeriod_Pre-Dubai-Food-Festival', 'IslamicPeriod_Pre-Dubai-Marathon', 'IslamicPeriod_Pre-Eid-Adha', 'IslamicPeriod_Pre-Flag-Day', 'IslamicPeriod_Pre-GITEX-Technology-Week', 'IslamicPeriod_Pre-Ramadan-Early', 'IslamicPeriod_Pre-Ramadan-Late', 'IslamicPeriod_Pre-UAE-National-Day', 'IslamicPeriod_Ramadan-First10Days', 'IslamicPeriod_Ramadan-Last10Days', 'IslamicPeriod_Ramadan-Middle']\n",
      "\n",
      "Removing original string columns: ['MealPeriod', 'IslamicPeriod']\n",
      "\n",
      "Concatenating one-hot encoded columns...\n",
      "\n",
      "Remaining string columns: []\n",
      "\n",
      "Final dataset shape: (1458, 58)\n",
      "Final columns: ['DayOfWeek', 'Month', 'Year', 'CheckTotal', 'is_zero', 'IsRamadan', 'IsEid', 'IsPreRamadan', 'IsPostRamadan', 'IsLast10Ramadan', 'IsDSF', 'IsSummerEvent', 'IsNationalDay', 'IsNewYear', 'IsMarathon', 'IsGITEX', 'IsAirshow', 'IsFoodFestival', 'IsPreEvent', 'IsPostEvent', 'TourismIntensity', 'RevenueImpact', 'MealPeriod_Breakfast', 'MealPeriod_Dinner', 'MealPeriod_Lunch', 'IslamicPeriod_Dubai-Airshow', 'IslamicPeriod_Dubai-Food-Festival', 'IslamicPeriod_Dubai-Marathon', 'IslamicPeriod_Dubai-Shopping-Festival', 'IslamicPeriod_Dubai-Summer-Surprises', 'IslamicPeriod_Eid-Adha', 'IslamicPeriod_Flag-Day', 'IslamicPeriod_GITEX-Technology-Week', 'IslamicPeriod_New-Year-Celebrations', 'IslamicPeriod_Normal', 'IslamicPeriod_Post-Dubai-Airshow', 'IslamicPeriod_Post-Dubai-Marathon', 'IslamicPeriod_Post-Eid-Adha', 'IslamicPeriod_Post-Flag-Day', 'IslamicPeriod_Post-GITEX-Technology-Week', 'IslamicPeriod_Post-New-Year-Celebrations', 'IslamicPeriod_Post-Ramadan-Recovery', 'IslamicPeriod_Post-Ramadan-Week1', 'IslamicPeriod_Post-Summer-Event', 'IslamicPeriod_Pre-Commemoration-Day', 'IslamicPeriod_Pre-DSF', 'IslamicPeriod_Pre-Dubai-Airshow', 'IslamicPeriod_Pre-Dubai-Food-Festival', 'IslamicPeriod_Pre-Dubai-Marathon', 'IslamicPeriod_Pre-Eid-Adha', 'IslamicPeriod_Pre-Flag-Day', 'IslamicPeriod_Pre-GITEX-Technology-Week', 'IslamicPeriod_Pre-Ramadan-Early', 'IslamicPeriod_Pre-Ramadan-Late', 'IslamicPeriod_Pre-UAE-National-Day', 'IslamicPeriod_Ramadan-First10Days', 'IslamicPeriod_Ramadan-Last10Days', 'IslamicPeriod_Ramadan-Middle']\n",
      "\n",
      "Sample of processed data:\n",
      "   DayOfWeek  Month  Year  CheckTotal  is_zero  IsRamadan  IsEid  \\\n",
      "0          6      1  2023      1499.4        0          0      0   \n",
      "1          6      1  2023      4374.5        0          0      0   \n",
      "2          6      1  2023      1260.0        0          0      0   \n",
      "3          0      1  2023       771.0        0          0      0   \n",
      "4          0      1  2023      3460.0        0          0      0   \n",
      "\n",
      "   IsPreRamadan  IsPostRamadan  IsLast10Ramadan  ...  \\\n",
      "0             0              0                0  ...   \n",
      "1             0              0                0  ...   \n",
      "2             0              0                0  ...   \n",
      "3             0              0                0  ...   \n",
      "4             0              0                0  ...   \n",
      "\n",
      "   IslamicPeriod_Pre-Dubai-Marathon  IslamicPeriod_Pre-Eid-Adha  \\\n",
      "0                                 0                           0   \n",
      "1                                 0                           0   \n",
      "2                                 0                           0   \n",
      "3                                 0                           0   \n",
      "4                                 0                           0   \n",
      "\n",
      "   IslamicPeriod_Pre-Flag-Day  IslamicPeriod_Pre-GITEX-Technology-Week  \\\n",
      "0                           0                                        0   \n",
      "1                           0                                        0   \n",
      "2                           0                                        0   \n",
      "3                           0                                        0   \n",
      "4                           0                                        0   \n",
      "\n",
      "   IslamicPeriod_Pre-Ramadan-Early  IslamicPeriod_Pre-Ramadan-Late  \\\n",
      "0                                0                               0   \n",
      "1                                0                               0   \n",
      "2                                0                               0   \n",
      "3                                0                               0   \n",
      "4                                0                               0   \n",
      "\n",
      "   IslamicPeriod_Pre-UAE-National-Day  IslamicPeriod_Ramadan-First10Days  \\\n",
      "0                                   0                                  0   \n",
      "1                                   0                                  0   \n",
      "2                                   0                                  0   \n",
      "3                                   0                                  0   \n",
      "4                                   0                                  0   \n",
      "\n",
      "   IslamicPeriod_Ramadan-Last10Days  IslamicPeriod_Ramadan-Middle  \n",
      "0                                 0                             0  \n",
      "1                                 0                             0  \n",
      "2                                 0                             0  \n",
      "3                                 0                             0  \n",
      "4                                 0                             0  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "\n",
      "✓ Dataset saved as 'dataset_no_strings_encoded.csv'\n"
     ]
    }
   ],
   "source": [
    "# Identify and handle all string columns\n",
    "print(\"Original columns:\", raw.columns.tolist())\n",
    "print(\"Data types:\")\n",
    "print(raw.dtypes)\n",
    "\n",
    "# Make a copy to work with\n",
    "raw_processed = raw.copy()\n",
    "\n",
    "# Step 1: Drop columns that shouldn't be encoded\n",
    "columns_to_drop = ['Date', 'RevenueCenterName']\n",
    "print(f\"\\nDropping non-feature columns: {columns_to_drop}\")\n",
    "raw_processed = raw_processed.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Step 2: Identify all remaining string/object columns\n",
    "string_columns = raw_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nString columns to one-hot encode: {string_columns}\")\n",
    "\n",
    "# Step 3: One-hot encode all string columns\n",
    "encoded_dataframes = []\n",
    "\n",
    "for col in string_columns:\n",
    "    print(f\"\\nOne-hot encoding '{col}':\")\n",
    "    unique_values = raw_processed[col].unique()\n",
    "    print(f\"  Unique values: {unique_values}\")\n",
    "    \n",
    "    # Create one-hot encoded columns\n",
    "    col_dummies = pd.get_dummies(raw_processed[col], prefix=col).astype(int)  # Convert to 0/1\n",
    "    print(f\"  Created columns: {col_dummies.columns.tolist()}\")\n",
    "    \n",
    "    # Store for concatenation\n",
    "    encoded_dataframes.append(col_dummies)\n",
    "\n",
    "# Step 4: Remove original string columns\n",
    "print(f\"\\nRemoving original string columns: {string_columns}\")\n",
    "raw_processed = raw_processed.drop(string_columns, axis=1)\n",
    "\n",
    "# Step 5: Concatenate all one-hot encoded columns\n",
    "if encoded_dataframes:\n",
    "    print(\"\\nConcatenating one-hot encoded columns...\")\n",
    "    all_encoded = pd.concat(encoded_dataframes, axis=1)\n",
    "    raw_processed = pd.concat([raw_processed, all_encoded], axis=1)\n",
    "\n",
    "# Step 6: Verify no string columns remain\n",
    "remaining_string_cols = raw_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nRemaining string columns: {remaining_string_cols}\")\n",
    "\n",
    "# Final result\n",
    "print(f\"\\nFinal dataset shape: {raw_processed.shape}\")\n",
    "print(f\"Final columns: {raw_processed.columns.tolist()}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample of processed data:\")\n",
    "print(raw_processed.head())\n",
    "\n",
    "# Save the processed dataset\n",
    "raw_processed.to_csv('dataset_no_strings_encoded.csv', index=False)\n",
    "print(\"\\n✓ Dataset saved as 'dataset_no_strings_encoded.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def transform_to_cnn_lstm_format(df):\n",
    "    \"\"\"\n",
    "    Transform your current dataset to CNN-LSTM ready format\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"TRANSFORMING DATASET FOR CNN-LSTM MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    print(f\"✓ Original shape: {df_processed.shape}\")\n",
    "    print(f\"✓ Original columns: {len(df_processed.columns)}\")\n",
    "    \n",
    "    # Step 1: Drop columns that won't be used as features\n",
    "    columns_to_drop = ['Date', 'RevenueCenterName']\n",
    "    \n",
    "    # Keep CheckTotal separate as target - we'll process it differently\n",
    "    target_data = df_processed[['Date', 'RevenueCenterName', 'MealPeriod', 'CheckTotal']].copy()\n",
    "    \n",
    "    print(f\"\\n✓ Dropping columns: {columns_to_drop}\")\n",
    "    df_processed = df_processed.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Step 2: One-hot encode categorical variables\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"CATEGORICAL ENCODING\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # One-hot encode MealPeriod\n",
    "    meal_dummies = pd.get_dummies(df_processed['MealPeriod'], prefix='Meal')\n",
    "    print(f\"✓ MealPeriod encoded to: {list(meal_dummies.columns)}\")\n",
    "    \n",
    "    # One-hot encode IslamicPeriod \n",
    "    islamic_dummies = pd.get_dummies(df_processed['IslamicPeriod'], prefix='Event')\n",
    "    print(f\"✓ IslamicPeriod encoded to: {len(islamic_dummies.columns)} event columns\")\n",
    "    \n",
    "    # One-hot encode TourismIntensity\n",
    "    tourism_dummies = pd.get_dummies(df_processed['TourismIntensity'], prefix='Tourism')\n",
    "    print(f\"✓ TourismIntensity encoded to: {list(tourism_dummies.columns)}\")\n",
    "    \n",
    "    # One-hot encode RevenueImpact\n",
    "    impact_dummies = pd.get_dummies(df_processed['RevenueImpact'], prefix='Impact')\n",
    "    print(f\"✓ RevenueImpact encoded to: {list(impact_dummies.columns)}\")\n",
    "    \n",
    "    # Drop original categorical columns\n",
    "    df_processed = df_processed.drop(columns=['MealPeriod', 'IslamicPeriod', 'TourismIntensity', 'RevenueImpact'])\n",
    "    \n",
    "    # Step 3: Create cyclical features for temporal variables\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"CYCLICAL FEATURE ENCODING\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Month cyclical encoding (1-12)\n",
    "    df_processed['Month_sin'] = np.sin(2 * np.pi * df_processed['Month'] / 12)\n",
    "    df_processed['Month_cos'] = np.cos(2 * np.pi * df_processed['Month'] / 12)\n",
    "    print(\"✓ Month encoded to cyclical features\")\n",
    "    \n",
    "    # DayOfWeek cyclical encoding (0-6)\n",
    "    df_processed['DayOfWeek_sin'] = np.sin(2 * np.pi * df_processed['DayOfWeek'] / 7)\n",
    "    df_processed['DayOfWeek_cos'] = np.cos(2 * np.pi * df_processed['DayOfWeek'] / 7)\n",
    "    print(\"✓ DayOfWeek encoded to cyclical features\")\n",
    "    \n",
    "    # Drop original temporal columns\n",
    "    df_processed = df_processed.drop(columns=['Month', 'DayOfWeek'])\n",
    "    \n",
    "    # Step 4: Combine all features\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"COMBINING ALL FEATURES\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Combine all one-hot encoded features\n",
    "    df_final = pd.concat([\n",
    "        df_processed,  # Numeric features\n",
    "        meal_dummies,  # Meal period dummies\n",
    "        islamic_dummies,  # Event dummies  \n",
    "        tourism_dummies,  # Tourism intensity dummies\n",
    "        impact_dummies  # Revenue impact dummies\n",
    "    ], axis=1)\n",
    "    \n",
    "    print(f\"✓ Combined shape: {df_final.shape}\")\n",
    "    print(f\"✓ Total features: {len(df_final.columns)}\")\n",
    "    \n",
    "    # Step 5: Scale all features\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"FEATURE SCALING\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(df_final),\n",
    "        columns=df_final.columns,\n",
    "        index=df_final.index\n",
    "    )\n",
    "    \n",
    "    print(\"✓ All features scaled using StandardScaler\")\n",
    "    print(f\"✓ Final dataset shape: {df_scaled.shape}\")\n",
    "    \n",
    "    # Step 6: Show sample of transformed data\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"SAMPLE OF TRANSFORMED DATA\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"First 5 rows, first 10 columns:\")\n",
    "    print(df_scaled.iloc[:5, :10].round(3))\n",
    "    \n",
    "    print(\"\\nColumn names (first 20):\")\n",
    "    print(list(df_scaled.columns[:20]))\n",
    "    \n",
    "    # Step 7: Feature summary\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"FEATURE BREAKDOWN\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    feature_counts = {\n",
    "        'Numeric Features': len([col for col in df_scaled.columns if not any(prefix in col for prefix in ['Meal_', 'Event_', 'Tourism_', 'Impact_', '_sin', '_cos'])]),\n",
    "        'Meal Features': len([col for col in df_scaled.columns if col.startswith('Meal_')]),\n",
    "        'Event Features': len([col for col in df_scaled.columns if col.startswith('Event_')]),\n",
    "        'Tourism Features': len([col for col in df_scaled.columns if col.startswith('Tourism_')]),\n",
    "        'Impact Features': len([col for col in df_scaled.columns if col.startswith('Impact_')]),\n",
    "        'Cyclical Features': len([col for col in df_scaled.columns if col.endswith(('_sin', '_cos'))])\n",
    "    }\n",
    "    \n",
    "    for feature_type, count in feature_counts.items():\n",
    "        print(f\"✓ {feature_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\n✓ TOTAL FEATURES: {sum(feature_counts.values())}\")\n",
    "    \n",
    "    return df_scaled, scaler, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1453    4\n",
       "1454    4\n",
       "1455    4\n",
       "1456    4\n",
       "1457    4\n",
       "Name: Month, Length: 1458, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[\"Month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRANSFORMING DATASET FOR CNN-LSTM MODEL\n",
      "============================================================\n",
      "✓ Original shape: (1458, 26)\n",
      "✓ Original columns: 26\n",
      "\n",
      "✓ Dropping columns: ['Date', 'RevenueCenterName']\n",
      "\n",
      "========================================\n",
      "CATEGORICAL ENCODING\n",
      "========================================\n",
      "✓ MealPeriod encoded to: ['Meal_Breakfast', 'Meal_Dinner', 'Meal_Lunch']\n",
      "✓ IslamicPeriod encoded to: 33 event columns\n",
      "✓ TourismIntensity encoded to: ['Tourism_0', 'Tourism_1', 'Tourism_2', 'Tourism_3']\n",
      "✓ RevenueImpact encoded to: ['Impact_-1', 'Impact_0', 'Impact_1']\n",
      "\n",
      "========================================\n",
      "CYCLICAL FEATURE ENCODING\n",
      "========================================\n",
      "✓ Month encoded to cyclical features\n",
      "✓ DayOfWeek encoded to cyclical features\n",
      "\n",
      "========================================\n",
      "COMBINING ALL FEATURES\n",
      "========================================\n",
      "✓ Combined shape: (1458, 65)\n",
      "✓ Total features: 65\n",
      "\n",
      "========================================\n",
      "FEATURE SCALING\n",
      "========================================\n",
      "✓ All features scaled using StandardScaler\n",
      "✓ Final dataset shape: (1458, 65)\n",
      "\n",
      "========================================\n",
      "SAMPLE OF TRANSFORMED DATA\n",
      "========================================\n",
      "First 5 rows, first 10 columns:\n",
      "    Year  CheckTotal  is_zero  IsRamadan  IsEid  IsPreRamadan  IsPostRamadan  \\\n",
      "0 -0.576       0.016   -0.083     -0.646 -0.185        -0.308         -0.308   \n",
      "1 -0.576       2.073   -0.083     -0.646 -0.185        -0.308         -0.308   \n",
      "2 -0.576      -0.156   -0.083     -0.646 -0.185        -0.308         -0.308   \n",
      "3 -0.576      -0.506   -0.083     -0.646 -0.185        -0.308         -0.308   \n",
      "4 -0.576       1.418   -0.083     -0.646 -0.185        -0.308         -0.308   \n",
      "\n",
      "   IsLast10Ramadan  IsDSF  IsSummerEvent  \n",
      "0           -0.207 -0.261         -0.389  \n",
      "1           -0.207 -0.261         -0.389  \n",
      "2           -0.207 -0.261         -0.389  \n",
      "3           -0.207 -0.261         -0.389  \n",
      "4           -0.207 -0.261         -0.389  \n",
      "\n",
      "Column names (first 20):\n",
      "['Year', 'CheckTotal', 'is_zero', 'IsRamadan', 'IsEid', 'IsPreRamadan', 'IsPostRamadan', 'IsLast10Ramadan', 'IsDSF', 'IsSummerEvent', 'IsNationalDay', 'IsNewYear', 'IsMarathon', 'IsGITEX', 'IsAirshow', 'IsFoodFestival', 'IsPreEvent', 'IsPostEvent', 'Month_sin', 'Month_cos']\n",
      "\n",
      "========================================\n",
      "FEATURE BREAKDOWN\n",
      "========================================\n",
      "✓ Numeric Features: 18\n",
      "✓ Meal Features: 3\n",
      "✓ Event Features: 33\n",
      "✓ Tourism Features: 4\n",
      "✓ Impact Features: 3\n",
      "✓ Cyclical Features: 4\n",
      "\n",
      "✓ TOTAL FEATURES: 65\n",
      "\n",
      "✓ Transformed dataset saved as 'cnn_lstm_ready_dataset.csv'\n",
      "✓ Target data saved as 'target_data_for_sequences.csv'\n"
     ]
    }
   ],
   "source": [
    "# Apply the transformation to your raw dataframe\n",
    "df_transformed, scaler, target_data = transform_to_cnn_lstm_format(raw)\n",
    "\n",
    "# Save the transformed dataset\n",
    "df_transformed.to_csv('cnn_lstm_ready_dataset.csv', index=False)\n",
    "print(f\"\\n✓ Transformed dataset saved as 'cnn_lstm_ready_dataset.csv'\")\n",
    "\n",
    "# Save the target data separately for sequence creation\n",
    "target_data.to_csv('target_data_for_sequences.csv', index=False)\n",
    "print(f\"✓ Target data saved as 'target_data_for_sequences.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
